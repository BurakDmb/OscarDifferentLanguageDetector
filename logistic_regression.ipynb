{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/15 23:44:03 WARN Utils: Your hostname, bhdemirbilek resolves to a loopback address: 127.0.1.1; using 10.1.46.97 instead (on interface eno1)\n",
      "22/01/15 23:44:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/bhdemirbilek/miniconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/01/15 23:44:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.setMaster(\"local[*]\").setAppName(\"CENG790-Project\")\n",
    "conf.set(\"spark.driver.memory\", \"15g\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Saving the oscar dataset(28GB) to json format. (only execute once)\n",
    "# from datasets import load_from_disk\n",
    "# dataset = load_from_disk(\"lang_detected\")[\"train\"]\n",
    "# # Set num_proc according to your cpu count, num_proc=20 means 20 thread will be executed paralelly.\n",
    "# dataset.to_json(\"dataset_json\", num_proc=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Reads from the dataset_json.json file, \n",
    "df_json = spark.read.json(\"dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------------------+\n",
      "| id|lang|                text|\n",
      "+---+----+--------------------+\n",
      "|  0|  tr|Son yıllarda görü...|\n",
      "|  1|  tr|Şehrin karmaşası ...|\n",
      "|  2|  tr|2010 Yılında Mard...|\n",
      "|  3|  tr|29Ekim 2009 2010 ...|\n",
      "|  4|  tr|Yüksek İslam Şura...|\n",
      "|  5|  tr|Oncelıkle bu etkı...|\n",
      "|  6|  tr|Mavi-Mi Sanat Mer...|\n",
      "|  7|  tr|Türkiye Futbol Fe...|\n",
      "|  8|  tr|anlami-nedir.com'...|\n",
      "|  9|  tr|Kepez Belediye Ba...|\n",
      "+---+----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "small_df = df_json.limit(10000)\n",
    "small_df.show(10)\n",
    "small_df.write.mode(\"overwrite\").json(\"dataset_small.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "small_df2 = spark.read.json(\"dataset_small.json\").select(\"lang\", \"text\")\n",
    "#small_df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(small_df2)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "# alternatively, CountVectorizer can also be used to get term frequency vectors\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledDataWithLang = idfModel.transform(featurizedData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[lang: string, text: string, words: array<string>, rawFeatures: vector, features: vector]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaledDataWithLang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"lang\", outputCol=\"label\")\n",
    "rescaledData = indexer.fit(rescaledDataWithLang).transform(rescaledDataWithLang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[lang: string, text: string, words: array<string>, rawFeatures: vector, features: vector, label: double]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rescaledData.count())\n",
    "rescaledData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/15 23:46:08 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rescaledData.select(\"features\", \"label\").write.mode(\"overwrite\").json(\"dataset_small_rescaled.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(262144,[2054,477...|  0.0|\n",
      "|(262144,[5612,155...|  0.0|\n",
      "|(262144,[550,1693...|  0.0|\n",
      "|(262144,[448,1512...|  0.0|\n",
      "|(262144,[2054,276...|  0.0|\n",
      "|(262144,[1004,107...|  0.0|\n",
      "|(262144,[5612,177...|  0.0|\n",
      "|(262144,[6,3720,3...|  0.0|\n",
      "|(262144,[3023,720...|  0.0|\n",
      "|(262144,[1219,214...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType\n",
    "\n",
    "schema = StructType([StructField('features', VectorUDT(),False), StructField('label', DoubleType(),False)])\n",
    "\n",
    "rescaledData = spark.read.schema(schema=schema).json(\"dataset_small_rescaled.json\")\n",
    "rescaledData.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(262144,[2054,477...|\n",
      "+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: double]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaledData.select(\"label\", \"features\").show(1)\n",
    "rescaledData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = rescaledData.select(\"label\", \"features\").randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/15 23:46:15 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = spark \\\n",
    "    .read \\\n",
    "    .format(\"libsvm\") \\\n",
    "    .load(\"sample_multiclass_classification_data.txt\")\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=100, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      "3 X 4 CSRMatrix\n",
      "(0,3) 0.3053\n",
      "(1,2) -0.7885\n",
      "(1,3) -0.3633\n",
      "Intercept: [0.050824384014652994,-0.12360035368876093,0.07277596967410795]\n",
      "objectiveHistory:\n",
      "1.098612288668108\n",
      "1.087602085441699\n",
      "1.0341156572156232\n",
      "1.0289859520256008\n",
      "1.0300389657358993\n",
      "1.0239965158223991\n",
      "1.0236097451839508\n",
      "1.023108212197001\n",
      "1.023022220302788\n",
      "1.0230018151780265\n",
      "1.0229963739557606\n",
      "1.0229911245659569\n",
      "1.0229874340180964\n",
      "1.0229860342712205\n",
      "1.0229832902098992\n",
      "1.0229817403940862\n",
      "1.0229813578951676\n",
      "1.0229811458425946\n",
      "1.0229809219195842\n",
      "1.0229808777096137\n",
      "1.0229808456821092\n",
      "1.022980838296153\n",
      "1.0229808366282138\n",
      "1.022980836270468\n",
      "1.0229808361102433\n",
      "1.0229808360601507\n",
      "1.0229808360560266\n",
      "1.0229808360545576\n",
      "1.022980836051717\n",
      "False positive rate by label:\n",
      "label 0: 0.22\n",
      "label 1: 0.05\n",
      "label 2: 0.0\n",
      "True positive rate by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "label 2: 0.46\n",
      "Precision by label:\n",
      "label 0: 0.6944444444444444\n",
      "label 1: 0.9090909090909091\n",
      "label 2: 1.0\n",
      "Recall by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "label 2: 0.46\n",
      "F-measure by label:\n",
      "label 0: 0.819672131147541\n",
      "label 1: 0.9523809523809523\n",
      "label 2: 0.6301369863013699\n",
      "Accuracy: 0.82\n",
      "FPR: 0.09\n",
      "TPR: 0.82\n",
      "F-measure: 0.800730023276621\n",
      "Precision: 0.8678451178451179\n",
      "Recall: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for multinomial logistic regression\n",
    "print(\"Coefficients: \\n\" + str(lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel.interceptVector))\n",
    "\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f4343353fbec2fc34c82a1b09b4d6d1875d4968c8401340e52b24b1aadc6ad7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pyspark': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
